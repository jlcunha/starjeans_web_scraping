{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180b422a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82487e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T09:48:35.592622Z",
     "start_time": "2022-04-22T09:48:35.131006Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b54060",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58db0e70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:33:13.011611Z",
     "start_time": "2022-04-22T08:33:09.025149Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# URL\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# Request to URL\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# Beautiful soup object\n",
    "soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# ==================== pagination ======================================\n",
    "total_item = soup.find_all( 'h2', class_='load-more-heading' )[0].get('data-total')\n",
    "page_number = math.ceil( int( total_item ) / 36)\n",
    "url02 = url + '?page-size=' + str( int( page_number*36 ))\n",
    "page = requests.get( url02, headers=headers )\n",
    "soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# ======================= Product Data =======================\n",
    "products = soup.find( 'ul', class_='products-listing small' ) \n",
    "product_list = products.find_all( 'article', class_='hm-product-item')\n",
    "\n",
    "# product id\n",
    "product_id = [p.get( 'data-articlecode' ) for p in product_list]\n",
    "\n",
    "# product category\n",
    "product_category = [p.get( 'data-category' ) for p in product_list]\n",
    "\n",
    "# product name\n",
    "product_list = products.find_all( 'a', class_='link' )\n",
    "product_name = [p.get_text() for p in product_list]\n",
    "\n",
    "# product_price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]\n",
    "\n",
    "# create data frame\n",
    "data = pd.DataFrame( [product_id, product_name, product_price, product_category] ).T\n",
    "data.columns = ['product_id', 'product_name', 'price', 'product_category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e37bf3",
   "metadata": {},
   "source": [
    "## Data Collection by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8fc2ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:38:17.393450Z",
     "start_time": "2022-04-22T08:33:16.962753Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# empty dataframe\n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "# unique columns for all products\n",
    "aux = []\n",
    "\n",
    "df_pattern = pd.DataFrame( columns = ['Art. No.', 'Composition', 'Fit', 'Size'] )\n",
    "for i in range ( len( data ) ):\n",
    "\n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "    \n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# ==================== color name ==================================\n",
    "    product_list = soup.find_all( 'a', class_='filter-option miniature active') + soup.find_all( 'a', class_='filter-option miniature')\n",
    "    color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "    # product id\n",
    "    product_id = [p.get( 'data-articlecode' ) for p in product_list]\n",
    "\n",
    "    df_color = pd.DataFrame( [product_id, color_name] ).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "    \n",
    "    for j in range( len( df_color ) ):\n",
    "        # API Requests\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "\n",
    "        page = requests.get( url, headers=headers )\n",
    "\n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "        \n",
    "        # ====================== Product Name =================================\n",
    "        product_name = soup.find_all( 'h1', class_='primary product-item-headline')\n",
    "        product_name = product_name[0].get_text()\n",
    "        \n",
    "        # ====================== Product Price =================================\n",
    "        product_price = soup.find_all( 'div', class_='primary-row product-item-price')\n",
    "        product_price = re.findall('\\d+\\.?\\d+', product_price[0].get_text())[0]\n",
    "        \n",
    "        \n",
    "        # ==================== composition ==================================\n",
    "        product_composition_list = soup.find_all( 'div', class_='details-attributes-list-item' )\n",
    "        product_composition =[list( filter( None, p.get_text().split( '\\n' ) ) ) for p in product_composition_list]\n",
    "\n",
    "        # rename dataframe\n",
    "        df_composition = pd.DataFrame(product_composition).T\n",
    "        df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "        # delete first row\n",
    "        df_composition = df_composition.iloc[1:].fillna( method='ffill' )\n",
    "\n",
    "        # remove pocket lining, shell, pocket and lining\n",
    "        df_composition['Composition'] = df_composition['Composition'].str.replace( 'Pocket lining: ', '', regex=True )\n",
    "        df_composition['Composition'] = df_composition['Composition'].str.replace( 'Shell: ', '', regex=True )\n",
    "        df_composition['Composition'] = df_composition['Composition'].str.replace( 'Lining: ', '', regex=True )\n",
    "        df_composition['Composition'] = df_composition['Composition'].str.replace( 'Pocket: ', '', regex=True )\n",
    "\n",
    "        # garantee the same number of columns\n",
    "        df_composition = pd.concat( [df_pattern, df_composition] )\n",
    "\n",
    "        # rename columns\n",
    "        df_composition = df_composition[['Art. No.', 'Composition', 'Fit', 'Size']]\n",
    "        df_composition.columns = ['product_id', 'composition', 'fit', 'size']\n",
    "        df_composition['product_name'] = product_name\n",
    "        df_composition['product_price'] = product_price\n",
    "\n",
    "        # keep new columns if it show up\n",
    "        aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "        # merge data color + composition\n",
    "        df_composition = pd.merge( df_composition, df_color, how='left', on='product_id')\n",
    "        \n",
    "        df_composition = df_composition.drop_duplicates()\n",
    "        \n",
    "        # all products\n",
    "        df_compositions = pd.concat( [df_compositions, df_composition], axis=0 )\n",
    "        \n",
    "    \n",
    "# generate style id + color id\n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply( lambda x: x[:-3])\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply( lambda x: x[-3:])\n",
    "\n",
    "# scrapy datetime\n",
    "df_compositions['scrapy_datetime'] = datetime.now().strftime( '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760623f0",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10dd0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:38:17.488333Z",
     "start_time": "2022-04-22T08:38:17.395278Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# product id\n",
    "df_data = df_compositions.dropna( subset=['product_id'])\n",
    "\n",
    "# product_name\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\n', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\t', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('  ', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace(' ', '_').str.lower()\n",
    "\n",
    "# product_price\n",
    "df_data['product_price'] = df_data['product_price'].astype( float )\n",
    "\n",
    "# color_name\n",
    "df_data['color_name'] = df_data['color_name'].str.replace( ' ', '_' ).str.lower ()\n",
    "\n",
    "# fit\n",
    "df_data['fit'] = df_data['fit'].apply( lambda x: x.replace( ' ', '_' ).lower() if pd.notnull( x ) else x)\n",
    "\n",
    "# size leg\n",
    "df_data['size_leg'] = df_data['size'].apply( lambda x: re.search( '(\\d{2}\\.\\d) cm', x ).group(1) if pd.notnull(x) else x)\n",
    "\n",
    "# size number\n",
    "df_data['size_number'] = df_data['size'].apply( lambda x: re.search('Size (.+)', x).group(1).replace( ')', '') if pd.notnull(x) else x)\n",
    "\n",
    "# ============================ composition ===========================================\n",
    "# break composition by comma\n",
    "df1 = df_data['composition'].str.split(',', expand=True).reset_index(drop=True)\n",
    "\n",
    "# coton | polyester | spandex\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df_data)), columns=['cotton', 'polyester', 'spandex'])\n",
    "\n",
    "# ------------------- coton -------------------\n",
    "df_cotton_0 = df1.loc[df1[0].str.contains( 'Cotton', na=True), 0]\n",
    "df_cotton_0.name = 'cotton'\n",
    "\n",
    "df_cotton_1 = df1.loc[df1[1].str.contains( 'Cotton', na=True), 1]\n",
    "df_cotton_1.name = 'cotton'\n",
    "\n",
    "# combine\n",
    "df_cotton = df_cotton_0.combine_first( df_cotton_1)\n",
    "\n",
    "df_ref = pd.concat( [df_ref, df_cotton], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last')]\n",
    "\n",
    "# ------------------- polyester -------------------\n",
    "df_polyester_0 = df1.loc[df1[0].str.contains( 'Polyester', na=True), 0]\n",
    "df_polyester_0.name = 'polyester'\n",
    "\n",
    "df_polyester_1 = df1.loc[df1[1].str.contains( 'Polyester', na=True), 1]\n",
    "df_polyester_1.name = 'polyester'\n",
    "\n",
    "# combine\n",
    "df_polyester = df_polyester_0.combine_first( df_polyester_1 )\n",
    "\n",
    "df_ref = pd.concat( [df_ref, df_polyester], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last')]\n",
    "\n",
    "# ------------------- spandex -------------------\n",
    "df_spandex_1 = df1.loc[df1[1].str.contains( 'Spandex', na=True), 1]\n",
    "df_spandex_1.name = 'spandex'\n",
    "\n",
    "df_spandex_2 = df1.loc[df1[2].str.contains( 'Spandex', na=True), 2]\n",
    "df_spandex_2.name = 'spandex'\n",
    "\n",
    "df_spandex_3 = df1.loc[df1[3].str.contains( 'Spandex', na=True), 3]\n",
    "df_spandex_3.name = 'spandex'\n",
    "\n",
    "# combine spandex from both columns 1 and 2\n",
    "df_spandex_c2 = df_spandex_1.combine_first( df_spandex_2)\n",
    "df_spandex = df_spandex_c2.combine_first( df_spandex_3)\n",
    "\n",
    "df_ref = pd.concat( [df_ref, df_spandex], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last')]\n",
    "\n",
    "# join of combine with product_id\n",
    "df_aux = pd.concat( [df_data['product_id'].reset_index(drop=True),df_ref], axis=1)\n",
    "\n",
    "# format composition df_data\n",
    "df_aux['cotton'] = df_aux['cotton'].apply( lambda x: int( re.search('\\d+', x).group(0) ) / 100 if pd.notnull( x ) else x)\n",
    "df_aux['polyester'] = df_aux['polyester'].apply( lambda x: int( re.search('\\d+', x).group(0) ) / 100 if pd.notnull( x ) else x)\n",
    "df_aux['spandex'] = df_aux['spandex'].apply( lambda x: int( re.search('\\d+', x).group(0) ) / 100 if pd.notnull( x ) else x)\n",
    "\n",
    "# final join\n",
    "df_aux = df_aux.groupby( 'product_id' ).max().reset_index().fillna( 0 )\n",
    "\n",
    "df_data = pd.merge( df_data, df_aux, on='product_id', how='left' )\n",
    "\n",
    "# Drop columns\n",
    "df_data = df_data.drop( columns=['size', 'composition'], axis=1 )\n",
    "\n",
    "# Drop duplicates\n",
    "df_data = df_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e4b723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:38:17.509790Z",
     "start_time": "2022-04-22T08:38:17.489814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>fit</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>color_name</th>\n",
       "      <th>style_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "      <th>size_leg</th>\n",
       "      <th>size_number</th>\n",
       "      <th>cotton</th>\n",
       "      <th>polyester</th>\n",
       "      <th>spandex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>19.99</td>\n",
       "      <td>black</td>\n",
       "      <td>1024256</td>\n",
       "      <td>001</td>\n",
       "      <td>2022-04-22 05:38:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024256002</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>19.99</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>1024256</td>\n",
       "      <td>002</td>\n",
       "      <td>2022-04-22 05:38:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024256003</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>19.99</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>1024256</td>\n",
       "      <td>003</td>\n",
       "      <td>2022-04-22 05:38:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1024256004</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>19.99</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>1024256</td>\n",
       "      <td>004</td>\n",
       "      <td>2022-04-22 05:38:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1024256005</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>19.99</td>\n",
       "      <td>dark_blue</td>\n",
       "      <td>1024256</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-04-22 05:38:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id       fit product_name  product_price        color_name  \\\n",
       "0  1024256001  slim_fit   slim_jeans          19.99             black   \n",
       "2  1024256002  slim_fit   slim_jeans          19.99  light_denim_blue   \n",
       "4  1024256003  slim_fit   slim_jeans          19.99  light_denim_blue   \n",
       "6  1024256004  slim_fit   slim_jeans          19.99        denim_blue   \n",
       "8  1024256005  slim_fit   slim_jeans          19.99         dark_blue   \n",
       "\n",
       "  style_id color_id      scrapy_datetime size_leg size_number  cotton  \\\n",
       "0  1024256      001  2022-04-22 05:38:17      NaN         NaN    0.99   \n",
       "2  1024256      002  2022-04-22 05:38:17      NaN         NaN    0.99   \n",
       "4  1024256      003  2022-04-22 05:38:17      NaN         NaN    0.99   \n",
       "6  1024256      004  2022-04-22 05:38:17      NaN         NaN    0.99   \n",
       "8  1024256      005  2022-04-22 05:38:17      NaN         NaN    0.99   \n",
       "\n",
       "   polyester  spandex  \n",
       "0       0.65     0.01  \n",
       "2       0.65     0.01  \n",
       "4       0.65     0.01  \n",
       "6       0.65     0.01  \n",
       "8       0.65     0.01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be034f",
   "metadata": {},
   "source": [
    "# Data Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67feb740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T08:38:17.517168Z",
     "start_time": "2022-04-22T08:38:17.512844Z"
    }
   },
   "outputs": [],
   "source": [
    "data_insert = df_data[[\n",
    "    'product_id',\n",
    "    'style_id',\n",
    "    'color_id',\n",
    "    'product_name',\n",
    "    'color_name',\n",
    "    'fit',\n",
    "    'product_price',\n",
    "    'size_number',\n",
    "    'size_leg',\n",
    "    'cotton',\n",
    "    'polyester',\n",
    "    'spandex',\n",
    "    'scrapy_datetime'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00dd7151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T09:48:45.742845Z",
     "start_time": "2022-04-22T09:48:45.737362Z"
    }
   },
   "outputs": [],
   "source": [
    "query_showroom_schema = \"\"\"\n",
    "    CREATE TABLE vitrine(\n",
    "    product_id         TEXT,\n",
    "    style_id           TEXT,\n",
    "    color_id           TEXT,\n",
    "    product_name       TEXT,\n",
    "    color_name         TEXT,\n",
    "    fit                TEXT,\n",
    "    product_price      REAL,\n",
    "    size_number        TEXT,\n",
    "    size_leg           TEXT,\n",
    "    cotton             REAL,\n",
    "    polyester          REAL,\n",
    "    spandex            REAL,\n",
    "    scrapy_datetime    TEXT\n",
    "    )\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e624597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T09:48:56.575363Z",
     "start_time": "2022-04-22T09:48:56.565338Z"
    }
   },
   "outputs": [],
   "source": [
    "# create table\n",
    "conn = sqlite3.connect( 'database_hm.sqlite' )\n",
    "cursor = conn.execute( query_showroom_schema )\n",
    "conn.commit() \n",
    "\n",
    "# aqui usamos a coneccao pelo sqlite3 por criarmos o banco de dados nele. Ja que ele fica armazenado no computador.\n",
    "# mas usualmente utiliza-se a coneccao do sqlalchemy(create engine), ja que voce usa o banco de dados no servidor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c0936e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T09:48:59.681685Z",
     "start_time": "2022-04-22T09:48:59.645771Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_insert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m conn \u001b[38;5;241m=\u001b[39m create_engine( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///database_hm.sqlite\u001b[39m\u001b[38;5;124m'\u001b[39m, echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# data insert\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# index=false para nao dar erro de insersao, pq o index nao reseta\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data_insert\u001b[38;5;241m.\u001b[39mto_sql( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvitrine\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mconn, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_insert' is not defined"
     ]
    }
   ],
   "source": [
    "# create database connection\n",
    "conn = create_engine( 'sqlite:///database_hm.sqlite', echo=False )\n",
    "\n",
    "# data insert\n",
    "# index=false para nao dar erro de insersao, pq o index nao reseta\n",
    "data_insert.to_sql( 'vitrine', con=conn, if_exists='append', index=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e74881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
